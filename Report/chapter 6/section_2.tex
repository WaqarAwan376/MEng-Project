\section{Future work}

The framework demonstrated in this report is its first version, and further testing and additional use cases are required, along with extensive validation. In this section, we will discuss the future roadmap for this project and how it can be further tested through practical applications to be considered \textit{``ready for use''}.

Currently, in the project, the probes can only extract data from static source code. This can be improved by adding probes that capture dynamic data from the software system, such as analyzing communication between services through messaging queues and collecting real-time information on REST API traffic. This could be achieved by probes that continuously monitor logs and transfer data to the SST server for further processing.

The probes currently in use extract data through scripts. Each probe script must be written by developers with domain or project knowledge. Various methods can be used to extract data from source code, including external tools that scan and analyze it. These external tools can reduce the dependency on custom probes that require domain expertise to be written. Since data extraction from external tools is already well-tested, it might be more reliable, efficient, and applicable across a wider range of use cases and programming languages. Similarly, machine learning processing can be integrated to analyze the extracted data, and the results from this analysis could be used to create separate probes.

The framework can be tested by integrating it into a Continuous Integration (CI) process. This ensures that any code changes are immediately processed by the probes and visualized using SST. This way, real-time analysis and insights can be produced, which will help developers monitor and assess the impact of changes on the source code.

Lastly, the framework can be tested on an enterprise-level application with a large number of probes. This will help evaluate the data handling capabilities of the SST tool and ensure that it does not face performance or reliability issues. Many reverse engineering tools struggle with these aspects when dealing with large datasets, so this testing will be crucial for validating the toolâ€™s efficiency and stability.
