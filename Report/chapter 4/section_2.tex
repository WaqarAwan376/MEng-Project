\section{Implementing Probes for Data Collection and Analysis}\label{sec:probes_implementation}

In the previous section, we discussed how the single source of truth works and how probes are registered and integrated with it. In this section, we will focus on the implementation of probes to demonstrate the functionality of the framework and validate the scenarios outlined in~\autoref{ch3:validation_roadmap}.  

We will cover only the key aspects of the implementation to provide a clear understanding of the process to the reader. For those interested in exploring the complete implementation in detail, the full source code is available at the Project's GitHub Repository\footnote{\url{https://github.com/WaqarAwan376/MEng-Project/releases/tag/v1.0.0}}.

We have implemented classes for each node and edge to keep the code consistent and ensure that all objects follow the same structure. We have also created classes to define relationships between nodes, ensuring that the data remains consistent for similar objects.

\subsection{Authors and Version Control}

As mentioned in~\autoref{ch3-sec:technical_validation_strategy}, we have merged the discussion and implementation of probes related to authors/contributors. We have discussed that an effective way to retrieve data related to authors and their contributions is by using a \textit{version control system}. Version control systems inherently track all changes made to a codebase and store this information within the \texttt{.git} directory, which is typically hidden. This directory contains the complete history of modifications, including details about contributors, timestamps, and commit messages, making it a reliable source for extracting author-related data.

We have several Python\footnote{\url{https://www.python.org/}} scripts to extract information from a git directory. These scripts analyze data such as the relationship between two authors based on the number of files they have collaborated on, identifying all authors who worked on a method, determining the top contributor among them, and listing the authors of each file.

Each script relies on the \texttt{.git} directory and uses the \textit{Javalang library}\footnote{\url{https://pypi.org/project/javalang/}} to parse Java source code. This library helps navigate Java code structure using \textit{Abstract Syntax Tree (AST)}, making it easier to extract relevant information. After parsing the Java source code, we extract author details of each line of the source code using the git blame command\footnote{\url{https://git-scm.com/docs/git-blame}}.

Once the author's information is extracted, it is stored in a JSON file and sent to SST for further processing and analysis.

For the sake of demonstrating the probe structure, we can take method contribution as an example to show the JSON structure for probes related to authors. Appendix \ref{appendix_sec:author_method_contributions} provides a sample JSON representation for the author method contribution probe. This example illustrates that the \texttt{Owner.java} file contains the \texttt{Owner} class, which includes the \texttt{getPetsInternal()} method. Rest of the probes related to authors can be explored in the project repository.

\subsection{Microservices REST API endpoints}

In~\autoref{ch3-sec:technical_validation_strategy}, we discussed a strategy to extract REST API endpoints from \textit{Java Spring Framework} source code. The approach involves searching for relevant annotations and decorators in the source code and using them to identify endpoints. We apply this logic to extract the required information.  

\sloppy
In the implemented Python script, we first extract Java files from all services. Then, we use regular expressions to check if they contain annotations such as \texttt{@RestController}, \texttt{@RequestMapping}, \texttt{@GetMapping}, \texttt{@PostMapping}, and similar decorators. If a file includes these annotations, we extract the full route information and create class and endpoint nodes. This allows us to represent how a particular class maps to an endpoint through relational edges.

Appendix~\ref{appendix_sec:microservices_endpoints} shows a sample JSON for endpoint mapping. The JSON shows that file \texttt{VetResource.java} contains \texttt{VetResource} class. This class maps \texttt{/vets} endpoint.

\subsection{Java Beans Extraction}

Using a similar approach to extracting REST API endpoints, we can also extract Java beans from the source code. Java beans are created using specific annotations placed at the top of a class. These annotations indicate that the class is a Java bean, which will be managed by the Java Spring Framework.

In the Python script we have implemented, we search for \texttt{@Component}, \texttt{@Service}, \texttt{@Repository}, \texttt{@Controller}, and \texttt{@Configuration} annotations in the source code to identify beans.

Once the beans are found, we also extract their methods by searching for the \texttt{@Bean} annotation. In this script, we use \textit{javalang} to parse methods when identifying bean methods and Python regular expressions to find classes in the source code. After determining the beans and their methods, we create their nodes using Python classes in our code. This allows us to establish relational edges between them.

Appendix~\ref{appendix_sec:bean_classes_methods} shows a sample JSON for bean classes and methods mapping. The \texttt{AIBeanConfiguration.java} file contains \texttt{AIBeanConfiguration} class. This class has a bean method \texttt{loadBalancedWebClientBuilder()}.

\subsection{Java Dependencies Extraction}

Java services have a \textit{Project Object Model (POM)} file that contains information about the Maven project\footnote{\url{https://maven.apache.org/}} and how it is built. It is an XML file that includes a list of all project dependencies. We can use this file to extract dependencies and their versions.

In the Python script we have implemented, we use a lightweight Python XML parser\footnote{\url{https://docs.python.org/3/library/xml.etree.elementtree.html}} for this purpose. We parse the XML file, extract the dependencies from each service, and create nodes and edges based on this information. When a dependency is found in the POM file, a node is made using the dependency class in our code. These nodes are then linked to each other using edges to represent relationships between dependencies.

\sloppy
Appendix~\ref{appendix_sec:dependencies} shows a sample JSON for dependencies graphs. The POM file in \texttt{spring-petclinic-genai-service} contains \texttt{spring-ai-bom} dependency. The properties key of their relation includes further information about the dependency, showing its version, scope, and type.

\subsection{Runner script and How it works}

We have a Python runner script that is responsible for running each probe script. To manage these probes, we use a \texttt{probes\_list.py} script file, which contains a list of Python dictionaries. Each dictionary represents a probe and includes three key elements: \textit{runner\_command}, \textit{probe\_file}, and \textit{arguments}. The runner script iterates through this list, executing each probe and sending a \texttt{POST} request to the SST server to update it with the latest extracted data. The \texttt{probes\_list.py} script file can be seen in appendix \autoref{appendix_sec:probes_list}.

One of the key advantages of this approach is that probes do not have to be written exclusively in Python. As long as a probe is placed in the \texttt{probes} folder and its corresponding runner command and probe file are specified in \texttt{probes\_list.py} file with correct arguments, it can be executed in the same way as other probes. This flexibility allows for the integration of scripts written in different programming languages.  

The runner script ensures that the data sent to the SST server is always up-to-date, consistent, and valid. It takes the source directory of the target source code as a command-line argument, allowing users to specify the location of the project they want to analyze. Below is an example of how to run the script:

\begin{tcolorbox}[colback=gray!5, colframe=gray!20]
    \texttt{python runner.py \newline ${--}$SOURCE\_DIR "/Projects/spring-petclinic-microservices" \newline ${--}$DIR\_NAME "spring-petclinic-microservices"}
\end{tcolorbox}

This method ensures an efficient and automated way to extract and update data while maintaining consistency across different probes.

Appendix~\ref{appendix_sec:py_runner_script} shows the implementation of the runner script. The script parses the command-line argument passed to it and runs the probe from the probes list, producing outputs. It is important to note that the \texttt{runner.py} script only sends the probe's nodes and edges data. The registration of the probes must be done manually for now. The script uses the requests\footnote{\url{https://pypi.org/project/requests/}} Python dependency to send requests to the SST server.